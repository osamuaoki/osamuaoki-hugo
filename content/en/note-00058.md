---
title: Container with LXC/LXD (6)
date: 2023-11-30T00:00:00+00:00
categories:
  - desktop
  - english
tags:
  - lxc
draft: true
slug: lxc-6
---

Here is a series of memos of me trying to use LXC/LXD on Debian 12 (`bookworm`).

<!--
VMの話　1. [リモートのLXDインスタンスの画面をローカルから操作してVDI環境を構築する](https://gihyo.jp/admin/serial/01/ubuntu-recipe/0738) (2022-11-09)
XRDP利用でPROXY
  1. [開発日誌：LXD デスクトップRDP](https://note.com/koya0316/n/n4a0f6e095047) (2021-07-30)
  1. [LXD + Ubuntu 18.04 + MATE + xrdpでリモートデスクトップ環境を作る](https://qiita.com/330k/items/3fc42431d4d08b925541) (2021-03-09)
-->

## LXD with xrdp




## YAML data example to set profile=wayland_pipewire

Let me address more IPC sockets etc., here.

```
 $ cat wayland_full.yaml
```

This updated YAML data is designed to connect IPC sockets not just for Wayland
but also X, PulseAudio and Pipewire.  Also, this has `raw.idmap` entry.





<!--

https://documentation.ubuntu.com/lxd/en/latest/userns-idmap/
Idmaps for user namespace
LXD runs safe containers. This is achieved mostly through the use of user namespaces which make it possible to run containers unprivileged, greatly limiting the attack surface.

User namespaces work by mapping a set of UIDs and GIDs on the host to a set of UIDs and GIDs in the container.

For example, we can define that the host UIDs and GIDs from 100000 to 165535 may be used by LXD and should be mapped to UID/GID 0 through 65535 in the container.

As a result a process running as UID 0 in the container will actually be running as UID 100000.

Allocations should always be of at least 65536 UIDs and GIDs to cover the POSIX range including root (0) and nobody (65534).

Kernel support
User namespaces require a kernel >= 3.12, LXD will start even on older kernels but will refuse to start containers.

Allowed ranges
On most hosts, LXD will check /etc/subuid and /etc/subgid for allocations for the lxd user and on first start, set the default profile to use the first 65536 UIDs and GIDs from that range.

If the range is shorter than 65536 (which includes no range at all), then LXD will fail to create or start any container until this is corrected.

If some but not all of /etc/subuid, /etc/subgid, newuidmap (path lookup) and newgidmap (path lookup) can be found on the system, LXD will fail the startup of any container until this is corrected as this shows a broken shadow setup.

If none of those files can be found, then LXD will assume a 1000000000 UID/GID range starting at a base UID/GID of 1000000.

This is the most common case and is usually the recommended setup when not running on a system which also hosts fully unprivileged containers (where the container runtime itself runs as a user).

Varying ranges between hosts
The source map is sent when moving containers between hosts so that they can be remapped on the receiving host.

Different idmaps per container
LXD supports using different idmaps per container, to further isolate containers from each other. This is controlled with two per-container configuration keys, security.idmap.isolated and security.idmap.size.

Containers with security.idmap.isolated will have a unique ID range computed for them among the other containers with security.idmap.isolated set (if none is available, setting this key will simply fail).

Containers with security.idmap.size set will have their ID range set to this size. Isolated containers without this property set default to a ID range of size 65536; this allows for POSIX compliance and a nobody user inside the container.

To select a specific map, the security.idmap.base key will let you override the auto-detection mechanism and tell LXD what host UID/GID you want to use as the base for the container.

These properties require a container reboot to take effect.

Custom idmaps
LXD also supports customizing bits of the idmap, e.g. to allow users to bind mount parts of the host’s file system into a container without the need for any UID-shifting file system. The per-container configuration key for this is raw.idmap, and looks like:

both 1000 1000
uid 50-60 500-510
gid 100000-110000 10000-20000
The first line configures both the UID and GID 1000 on the host to map to UID 1000 inside the container (this can be used for example to bind mount a user’s home directory into a container).

The second and third lines map only the UID or GID ranges into the container, respectively. The second entry per line is the source ID, i.e. the ID on the host, and the third entry is the range inside the container. These ranges must be the same size.

This property requires a container reboot to take effect.

https://discuss.linuxcontainers.org/t/need-id-mapping-root-and-user-in-container-to-same-user-in-host/15461
Need ID mapping root and user in container to same user in host
...
This is not possible AFAIK. So what I did?

lxc config set t7 raw.idmap "both 1000 0"
This maps my user in the host (1000:1000) to the root user into the LXD container.

What did I get?: my docker containers running inside the LXD container can manage devices and resources as root, and they can access all the directory binds that I need (owned by user 1000:1000 in the host).


https://gihyo.jp/admin/serial/01/ubuntu-recipe/0479
第479回
LXDコンテナとホストの間でファイルを共有する方法


ホストのディレクトリーツリーをbind mountする
名前空間による制限により、コンテナからホストのルートファイルシステムを直接見ることはできません。またAppArmorにより、コンテナ内部からのブロックファイルのmountは禁止されています。もしコンテナとホストの間、もしくは同じホスト上のコンテナ間でファイルやディレクトリを共有したい場合は、コンテナの設定でbind mountする方法が便利です。

$ lxc config device add sample share disk source=/srv/shared path=/srv/shared
上記のコマンドはホストの/srv/shared（source=オプション）を、コンテナ内部の/srv/shared（path=オプション）としてbind mountします。つまりホストとコンテナで/srv/sharedを共有できるというわけです。

lxc configによる設定は永続的に反映されますので、コンテナの再起動を行ってもそのまま残っています。

$ lxc config show sample
（中略）
devices:
  nfsdir:
    path: /srv/shared
    source: /srv/shared
    type: disk
（後略）
この方法のメリットは、ホスト側のファイルシステムに関係なく同じ方法でコンテナと共有できることです。たとえばコンテナの内部からNFSディレクトリをmountする場合も、一度ホスト側でNFSディレクトリをmountしておけば、それをそのままコンテナにbind mountできるのです。よって同じホスト上のコンテナ間だけでなく、ネットワーク越しのコンテナ間ともファイルやディレクトリを共有できます。

ただしlxc fileと異なり、UID等のマッピングの変更は行いません。よってコンテナの一般ユーザーで作ったファイルやディレクトリのオーナーは、ホストから見るととても大きなUIDを持っていることになります。

ホストとコンテナでUID等を一致させる
bind mountによる共有ディレクトリを使う場合、ホストとコンテナで一般ユーザーのUID等を一致させたほうが便利です。つまりコンテナのUID=1000はホストでもUID=1000にします。もちろんrootを一致させるとそれはとどのつまり「ほぼ特権コンテナ」となりますので、非特権コンテナにしておく意味が薄れます。あくまで「普段使うユーザー」のみUIDを一致させるのです。理想的にはそのユーザーはsudoグループに入っていないほうがいいでしょう。
gg
UID等のマッピングは/etc/subuid、/etc/subgidファイルで管理しています。UID=1000、GID=1000のユーザーとグループはホストとコンテナで一致したい場合は次のように設定します。

$ echo "root:1000:1" | sudo tee -a /etc/subuid
$ echo "root:1000:1" | sudo tee -a /etc/subgid
このうちrootは今回設定したUID等のマッピングを許可するユーザーです。LXDの場合はrootがコンテナ起動時にマッピングを行うのでrootにしています。書式は「USER:START:COUNT」です。上記設定の場合は、「⁠ID=1000から1つ」になります。もちろん「1」を「100」にして複数のUIDをマッピングすることも可能です。

コンテナ内部のマッピングに関する設定は、コンテナごとに行います。

$ lxc config set sample raw.idmap 'both 1000 1000'
「both」はUIDとGID両方に同じ値を設定するパラメーターです。書式は「both HOST_ID CONTAINER_ID」となります。HOST_IDにはホスト上のUID/GIDを、CONTAINER_IDにはHOST_IDをコンテナの中にマップした時のIDを記述します。言い換えると「ホスト上のUID/GID 1000をコンテナ上のUID/GID 1000として扱う」ということです。

もしUID/GIDを異なる値にしたい場合はbothのかわりにuidやgidを使います。

ホスト上のUID=1010をコンテナ上ではUID=1000として扱いたい場合
uid 1010 1000

ホスト上のGID=1011をコンテナ上ではGID=1000として扱いたい場合
gid 1011 1000
uidとgidを同時に設定したい場合は、改行でつなぎます。しかしながらlxc configコマンドは直接改行を扱えません。そこで設定内容を標準入力から受け付けるようにして、そこにパイプで設定内容を流し込みます。

$ echo -e "uid 1010 1000\ngid 1011 1000" | lxc config set xenial raw.idmap -
ハイフンをつないで範囲を指定することも可能です。この場合、マッピング元とマッピング先の個数が同じになるようにしてください。

変更した設定を反映するには、一度そのコンテナを再起動します。冒頭と同じようにプロセスのUIDをコンテナとホストで比べたら、UID=0はマッピングされているものの、UID=1000はコンテナとホストで一致していることがわかるはずです。

これらを組み合わせれば、ホスト・コンテナ間のファイルやディレクトリのアクセス権をそれなりにコントロールできることでしょう。
---------------
https://stgraber.org/2017/06/15/custom-user-mappings-in-lxd-containers/
Introduction
As you may know, LXD uses unprivileged containers by default.
The difference between an unprivileged container and a privileged one is whether the root user in the container is the “real” root user (uid 0 at the kernel level).

The way unprivileged containers are created is by taking a set of normal UIDs and GIDs from the host, usually at least 65536 of each (to be POSIX compliant) and mapping those into the container.

The most common example and what most LXD users will end up with by default is a map of 65536 UIDs and GIDs, with a host base id of 100000. This means that root in the container (uid 0) will be mapped to the host uid 100000 and uid 65535 in the container will be mapped to uid 165535 on the host. UID/GID 65536 and higher in the container aren’t mapped and will return an error if you attempt to use them.

From a security point of view, that means that anything which is not owned by the users and groups mapped into the container will be inaccessible. Any such resource will show up as being owned by uid/gid “-1” (rendered as 65534 or nobody/nogroup in userspace). It also means that should there be a way to escape the container, even root in the container would find itself with just as much privileges on the host as a nobody user.

LXD does offer a number of options related to unprivileged configuration:

Increasing the size of the default uid/gid map
Setting up per-container maps
Punching holes into the map to expose host users and groups
Increasing the size of the default map
As mentioned above, in most cases, LXD will have a default map that’s made of 65536 uids/gids.

In most cases you won’t have to change that. There are however a few cases where you may have to:

You need access to uid/gid higher than 65535.
This is most common when using network authentication inside of your containers.
You want to use per-container maps.
In which case you’ll need 65536 available uid/gid per container.
You want to punch some holes in your container’s map and need access to host uids/gids.
The default map is usually controlled by the “shadow” set of utilities and files. On systems where that’s the case, the “/etc/subuid” and “/etc/subgid” files are used to configure those maps.

On systems that do not have a recent enough version of the “shadow” package. LXD will assume that it doesn’t have to share uid/gid ranges with anything else and will therefore assume control of a billion uids and gids, starting at the host uid/gid 100000.

But the common case, is a system with a recent version of shadow.
An example of what the configuration may look like is:

stgraber@castiana:~$ cat /etc/subuid
lxd:100000:65536
root:100000:65536

stgraber@castiana:~$ cat /etc/subgid
lxd:100000:65536
root:100000:65536
The maps for “lxd” and “root” should always be kept in sync. LXD itself is restricted by the “root” allocation. The “lxd” entry is used to track what needs to be removed if LXD is uninstalled.

Now if you want to increase the size of the map available to LXD. Simply edit both of the files and bump the last value from 65536 to whatever size you need. I tend to bump it to a billion just so I don’t ever have to think about it again:

stgraber@castiana:~$ cat /etc/subuid
lxd:100000:1000000000
root:100000:1000000000

stgraber@castiana:~$ cat /etc/subgid
lxd:100000:1000000000
root:100000:100000000
After altering those files, you need to restart LXD to have it detect the new map:

root@vorash:~# systemctl restart lxd
root@vorash:~# cat /var/log/lxd/lxd.log
lvl=info msg="LXD 2.14 is starting in normal mode" path=/var/lib/lxd t=2017-06-14T21:21:13+0000
lvl=warn msg="CGroup memory swap accounting is disabled, swap limits will be ignored." t=2017-06-14T21:21:13+0000
lvl=info msg="Kernel uid/gid map:" t=2017-06-14T21:21:13+0000
lvl=info msg=" - u 0 0 4294967295" t=2017-06-14T21:21:13+0000
lvl=info msg=" - g 0 0 4294967295" t=2017-06-14T21:21:13+0000
lvl=info msg="Configured LXD uid/gid map:" t=2017-06-14T21:21:13+0000
lvl=info msg=" - u 0 1000000 1000000000" t=2017-06-14T21:21:13+0000
lvl=info msg=" - g 0 1000000 1000000000" t=2017-06-14T21:21:13+0000
lvl=info msg="Connecting to a remote simplestreams server" t=2017-06-14T21:21:13+0000
lvl=info msg="Expiring log files" t=2017-06-14T21:21:13+0000
lvl=info msg="Done expiring log files" t=2017-06-14T21:21:13+0000
lvl=info msg="Starting /dev/lxd handler" t=2017-06-14T21:21:13+0000
lvl=info msg="LXD is socket activated" t=2017-06-14T21:21:13+0000
lvl=info msg="REST API daemon:" t=2017-06-14T21:21:13+0000
lvl=info msg=" - binding Unix socket" socket=/var/lib/lxd/unix.socket t=2017-06-14T21:21:13+0000
lvl=info msg=" - binding TCP socket" socket=[::]:8443 t=2017-06-14T21:21:13+0000
lvl=info msg="Pruning expired images" t=2017-06-14T21:21:13+0000
lvl=info msg="Updating images" t=2017-06-14T21:21:13+0000
lvl=info msg="Done pruning expired images" t=2017-06-14T21:21:13+0000
lvl=info msg="Done updating images" t=2017-06-14T21:21:13+0000
root@vorash:~#
As you can see, the configured map is logged at LXD startup and can be used to confirm that the reconfiguration worked as expected.

You’ll then need to restart your containers to have them start using your newly expanded map.

Per container maps
Provided that you have a sufficient amount of uid/gid allocated to LXD, you can configure your containers to use their own, non-overlapping allocation of uids and gids.

This can be useful for two reasons:

You are running software which alters kernel resource ulimits.
Those user-specific limits are tied to a kernel uid and will cross container boundaries leading to hard to debug issues where one container can perform an action but all others are then unable to do the same.
You want to know that should there be a way for someone in one of your containers to somehow get access to the host that they still won’t be able to access or interact with any of the other containers.
The main downsides to using this feature are:

It’s somewhat wasteful with using 65536 uids and gids per container.
That being said, you’d still be able to run over 60000 isolated containers before running out of system uids and gids.
It’s effectively impossible to share storage between two isolated containers as everything written by one will be seen as -1 by the other. There is ongoing work around virtual filesystems in the kernel that will eventually let us get rid of that limitation.
To have a container use its own distinct map, simply run:

stgraber@castiana:~$ lxc config set test security.idmap.isolated true
stgraber@castiana:~$ lxc restart test
stgraber@castiana:~$ lxc config get test volatile.last_state.idmap
[{"Isuid":true,"Isgid":false,"Hostid":165536,"Nsid":0,"Maprange":65536},{"Isuid":false,"Isgid":true,"Hostid":165536,"Nsid":0,"Maprange":65536}]
The restart step is needed to have LXD remap the entire filesystem of the container to its new map.
Note that this step will take a varying amount of time depending on the number of files in the container and the speed of your storage.

As can be seen above, after restart, the container is shown to have its own map of 65536 uids/gids.

If you want LXD to allocate more than the default 65536 uids/gids to an isolated container, you can bump the size of the allocation with:

stgraber@castiana:~$ lxc config set test security.idmap.size 200000
stgraber@castiana:~$ lxc restart test
stgraber@castiana:~$ lxc config get test volatile.last_state.idmap
[{"Isuid":true,"Isgid":false,"Hostid":165536,"Nsid":0,"Maprange":200000},{"Isuid":false,"Isgid":true,"Hostid":165536,"Nsid":0,"Maprange":200000}]
If you’re trying to allocate more uids/gids than are left in LXD’s allocation, LXD will let you know:

stgraber@castiana:~$ lxc config set test security.idmap.size 2000000000
error: Not enough uid/gid available for the container.
Direct user/group mapping
The fact that all uids/gids in an unprivileged container are mapped to a normally unused range on the host means that sharing of data between host and container is effectively impossible.

Now, what if you want to share your user’s home directory with a container?

The obvious answer to that is to define a new “disk” entry in LXD which passes your home directory to the container:

stgraber@castiana:~$ lxc config device add test home disk source=/home/stgraber path=/home/ubuntu
Device home added to test
So that was pretty easy, but did it work?

stgraber@castiana:~$ lxc exec test -- bash
root@test:~# ls -lh /home/
total 529K
drwx--x--x 45 nobody nogroup 84 Jun 14 20:06 ubuntu
No. The mount is clearly there, but it’s completely inaccessible to the container.
To fix that, we need to take a few extra steps:

Allow LXD’s use of our user uid and gid
Restart LXD to have it load the new map
Set a custom map for our container
Restart the container to have the new map apply
stgraber@castiana:~$ printf "lxd:$(id -u):1\nroot:$(id -u):1\n" | sudo tee -a /etc/subuid
lxd:201105:1
root:201105:1

stgraber@castiana:~$ printf "lxd:$(id -g):1\nroot:$(id -g):1\n" | sudo tee -a /etc/subgid
lxd:200512:1
root:200512:1

stgraber@castiana:~$ sudo systemctl restart lxd

stgraber@castiana:~$ printf "uid $(id -u) 1000\ngid $(id -g) 1000" | lxc config set test raw.idmap -

stgraber@castiana:~$ lxc restart test
At which point, things should be working in the container:

stgraber@castiana:~$ lxc exec test -- su ubuntu -l
ubuntu@test:~$ ls -lh
total 119K
drwxr-xr-x 5  ubuntu ubuntu 8 Feb 18 2016 data
drwxr-x--- 4  ubuntu ubuntu 6 Jun 13 17:05 Desktop
drwxr-xr-x 3  ubuntu ubuntu 28 Jun 13 20:09 Downloads
drwx------ 84 ubuntu ubuntu 84 Sep 14 2016 Maildir
drwxr-xr-x 4  ubuntu ubuntu 4 May 20 15:38 snap
ubuntu@test:~$

Conclusion
User namespaces, the kernel feature that makes those uid/gid mappings possible is a very powerful tool which finally made containers on Linux safe by design. It is however not the easiest thing to wrap your head around and all of that uid/gid map math can quickly become a major issue.

In LXD we’ve tried to expose just enough of those underlying features to be useful to our users while doing the actual mapping math internally. This makes things like the direct user/group mapping above significantly easier than it otherwise would be.

Going forward, we’re very interested in some of the work around uid/gid remapping at the filesystem level, this would let us decouple the on-disk user/group map from that used for processes, making it possible to share data between differently mapped containers and alter the various maps without needing to also remap the entire filesystem.

Extra information
The main LXD website is at: https://linuxcontainers.org/lxd
Development happens on Github at: https://github.com/lxc/lxd
Discussion forun: https://discuss.linuxcontainers.org
Mailing-list support happens on: https://lists.linuxcontainers.org
IRC support happens in: #lxcontainers on irc.freenode.net
Try LXD online: https://linuxcontainers.org/lxd/try-it


----
https://stackoverflow.com/questions/71738168/linux-container-failed-to-set-up-id-mapping


your mappings look quite wrong... syntax should be :

/etc/subuid

[local unprivileged user on the host that will run the container]:[uid on the host start at(this is inexisting uid on the host and it is ok)]:[number/range of uid to map]

e.g : toto:100000:65535

/etc/subuid

[local unprivileged group on the host that will run the container]:[guid on the host start at(this is inexisting gid on the host and it is ok)]:[number/range of uid to map]

e.g : toto:100000:65535

config

then, in the config file of the container, if you want to restrict the access further, you can do some specific mappings:

lxc.idmap = u 0 100000 1

lxc.idmap = g 0 100000 1

lxc.idmap = u 33 100033 1

lxc.idmap = g 33 100033 1

will map the uid and gid 0 (root) in the container to uid and gid 100000 on the host

will map the uid and gid 33 (www-data) in the container to uid and gid 100033 on the host

--------------

LXDのコンテナ中でホストのホームディレクトリを読み書きする方法
https://qiita.com/m-shibata/items/2969ab84bab9235d25f0
https://ubuntu.com/blog/mounting-your-home-directory-in-lxd
Mounting your home directory in LXD
As of LXD stable 2.0.8 and feature release 2.6, LXD has support for various UID and GID map related manipulaions. A common question is: “How do I bind-mount my home directory into a container?” and before the answer was “well, it’s complicated but you can do it; it’s slightly less complicated if you do it in privleged containers”. However, with this feature, now you can do it very easily in unprivileged containers.

First, find out your uid on the host:

$ id
uid=1000(tycho) gid=1000(tycho) groups=1000(tycho),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),112(lpadmin),124(sambashare),129(libvirtd),149(lxd),150(sbuild)
On standard Ubuntu hosts, the uid of the first user is 1000. Now, we need to allow LXD to remap to remap this id; you’ll need an additional entry for root to do this:

$ echo 'root:1000:1' | sudo tee -a /etc/subuid /etc/subgid
Now, create a container, and set the idmap up to map both uid and gid 1000 to uid and gid 1000 inside the container.

$ lxc init ubuntu-daily:z zesty
Creating zesty

$ lxc config set zesty raw.idmap 'both 1000 1000'
Finally, set up your home directory to be mounted in the container:

$ lxc config device add zesty homedir disk source=/home/tycho path=/home/ubuntu
And leave an insightful message for users of the container:

$ echo 'meshuggah rocks' >> message
Finally, start your container and read the message:

$ lxc start zesty
$ lxc exec zesty cat /home/ubuntu/message
meshuggah rocks
And enjoy the insight offered to you by your home directory 🙂


Sunday, August 28, 2022
LXD Containers for Wayland GUI Apps
https://blog.swwomm.com/2022/08/lxd-containers-for-wayland-gui-apps.html

---
Install any OS via ISO in a Virtual machine/VM
https://discuss.linuxcontainers.org/t/install-any-os-via-iso-in-a-virtual-machine-vm/9281
Windows VM:
Take a look at: Running virtual machines with LXD 4.0 147
or:
How to run a Windows virtual machine on LXD on Linux 141

Linux VM:

Start an empty VM with:
Note: Change VM-name to a custom name you choose.

lxc init VM-name --empty --vm

Note: In some cases it might be required to disable SecureBoot, when it blocks the .iso file (Recommendation: Disable only when necessary!).
You can do this, either by adding -c security.secureboot=false to the init/launch command
or by modifying the config key of an existing VM with: lxc config set VM-name security.secureboot=false.

Grow the VMs filesystem size:
The default size is mostly too small.
You can choose what size you think is reasonable, in this example I use 15 Gigabyte (GB).

lxc config device override VM-name root size=15GB

Add the .iso file to the VM via a disk device:
Note: Adjust the values accordingly.

lxc config device add VM-name custom-device-name disk source=/home/user/pathtoiso/isoname.iso

Start the VM with GUI:
lxc start VM-name --console=vga

--console=vga will open a VGA console.

(Note: You maybe need to install additional software for this, see GUI in Virtual Machines/VMs)

Remove disk device:
After installation you can remove the disk device, with:
lxc config device remove VM-name device-name

(optional) Convert your VM to an image:
So you can use it in the future.

lxc publish VM-name --alias custom-image-name


-----------
https://ubuntu.com/tutorials/how-to-launch-an-instantly-functional-linux-desktop-vm-with-lxd#2-initiate-an-ubuntu-desktop-vm
How to launch an instantly functional Linux desktop VM with LXD

The full command for launching an Ubuntu 22.04 VM would then look like this:

lxc launch images:ubuntu/22.04/desktop ubuntu --vm -c limits.cpu=4 -c limits.memory=4GiB --console=vga


Launching an Archlinux Desktop VM is similar to what we’ve done previously with Ubuntu, with a single addition - disabling secure boot.

The full command for launching an Archlinux VM would then look like this:

lxc launch images:archlinux/desktop-gnome archlinux --vm -c security.secureboot=false -c limits.cpu=4 -c limits.memory=4GiB --console=vga



----------

How to run Docker inside LXD containers
https://ubuntu.com/tutorials/how-to-run-docker-inside-lxd-containers#1-overview

Btrfs is one of the storage pools Docker supports natively, so we should create a new btrfs storage pool and we will call it “docker”:

lxc storage create docker btrfs

Now we can create a new LXD instance and call it “demo”:

lxc launch images:ubuntu/20.04 demo

We can proceed and create a new storage volume on the “docker” storage pool created earlier:

lxc storage volume create docker demo

We will attach it to the “demo” container and call the device being added as “docker”. Source volume is “demo” we created earlier, and we want that volume to be used for /var/lib/docker:

lxc config device add demo docker disk pool=docker source=demo path=/var/lib/docker

We need to add additional configuration so that Docker works well inside the container.

First we should allow nested containers required for Docker. Then, there are two additional security options needed - to intercept and emulate system calls. This normally wouldn’t be allowed inside LXD default unprivileged containers, but Docker relies on it for its layers, so it is okay to enable it.

lxc config set demo security.nesting=true security.syscalls.intercept.mknod=true security.syscalls.intercept.setxattr=true

To apply these changes, we need to restart the instance:

lxc restart demo




3. Install Docker
To install Docker, we start by going inside the container:

lxc exec demo bash

Now we can follow the normal Docker installation instructions. Paste the following command:

sudo apt-get update

 sudo apt-get install \
 ca-certificates \
 curl \
 gnupg \
  lsb-release
Now we need to add Docker’s official GPG key:

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg \
--dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
And now we can install the Docker repository:

echo \
"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
Finally, we can install Docker itself:

sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io


4. Test your Docker container
Now we have Docker up and running. Let’s test it by running an Ubuntu Docker container:

docker run -it ubuntu bash

And we can run the following to check that the processes are running correctly:

ps aux

And that’s it! Now you have a working Ubuntu Docker container inside of an LXD container. You can use it, or you can spin up another Docker image and proceed to use it according to your needs.

5. Additional information
Vast majority of Docker images will run fine inside LXD containers. However, few might not run properly. The reason for this is that LXD runs all its container unprivileged by default, which limits some of the actions of the user. Docker, on the other hand, runs privileged containers, and some actions might expect more privileges than LXD gives them, causing potential failures. For example, if you’re running something inside a docker container that expects to run as root, it won’t be able to do actions as a real root user but rather only as root inside of the LXD container, which is more constrained.

-----
https://ubuntu.com/blog/howto-automatically-import-your-public-ssh-keys-into-lxd-instances
Just another reason why LXD is so awesome…

You can easily configure your own cloud-init configuration into your LXD instance profile.

In my case, I want cloud-init to automatically ssh-import-id kirkland, to fetch my keys from Launchpad.  Alternatively, I could use gh:dustinkirkland to fetch my keys from Github.

Here’s how!

First, edit your default LXD profile (or any other, for that matter):

$ lxc profile edit default
Then, add the config snippet, like this:

config:
  user.vendor-data: |
    #cloud-config
    users:
      - name: root
        ssh-import-id: gh:dustinkirkland
        shell: /bin/bash
description: Default LXD profile
devices:
  eth0:
    name: eth0
    nictype: bridged
    parent: lxdbr0
    type: nic
name: default
Save and quit in your interactive editor, and then launch a new instance:

$ lxc launch ubuntu:x
Creating amazed-manatee
Starting amazed-manatee
Find your instance’s IP address:

$ lxc list
+----------------+---------+----------------------+----------------------------------------------+------------+-----------+
|      NAME      |  STATE  |         IPV4         |                     IPV6                     |    TYPE    | SNAPSHOTS |
+----------------+---------+----------------------+----------------------------------------------+------------+-----------+
| amazed-manatee | RUNNING | 10.163.22.135 (eth0) | fdce:be5e:b787:f7d2:216:3eff:fe1c:773 (eth0) | PERSISTENT | 0         |
+----------------+---------+----------------------+----------------------------------------------+------------+-----------+
And now SSH in!

$ ssh ubuntu@10.163.22.135
$ ssh -6 ubuntu@fdce:be5e:b787:f7d2:216:3eff:fe1c:773
Enjoy!

:-Dustin

---------
https://ubuntu.com/blog/publishing-lxd-images
While some work remains to be done for ‘lxc publish’, the current support is sufficient to show a full cycle of image workload with lxd.

Ubuntu Wily comes with systemd by default. Sometimes you might need a Wily container with upstart. And to repeatedly reproduce some tests on Wily with upstart, you might want to create a container image.

# lxc remote add lxc images.linuxcontainers.org
# lxc launch lxc:ubuntu/wily/amd64 w1
# lxc exec w1 -- apt-get -y install upstart-bin upstart-sysv
# lxc stop w1
# lxc publish --public w1 --alias=wily-with-upstart
# lxc image copy wily-with-upstart remote:  # optional
Now you can start a new container using

# lxc launch wily-with-upstart w-test-1
# lxc exec w-test-1 -- ls -alh /sbin/init
lrwxrwxrwx 1 root root 7 May 18 10:20 /sbin/init -> upstart
# lxc exec w-test-1 run-my-tests

-------
https://www.cyberciti.biz/faq/how-to-add-or-mount-directory-in-lxd-linux-container/
How to add or mount directory in LXD (Linux container)
Author: Vivek Gite Last updated: September 18, 2023 9 comments
See all LXD related Howtos/TutorialsIhave two LXD containers running. One is for Nginx, and another is for processing data. I need to share data between two containers. How do I add or mount a shared directory between two?

One can manage devices of running containers using lxc command. To add devices such as directory to containers, use lxc config device add command. This page explains how to add a host directory to an LXD container
Tutorial details
Difficulty level	Intermediate
Root privileges	Yes
Requirements	Linux terminal
Category	LXD
Prerequisites	LXD
OS compatibility	Alma • Alpine • Arch • Debian • Fedora • Linux • Mint • openSUSE • Pop!_OS • RHEL • Rocky • Stream • SUSE • Ubuntu
Est. reading time	4 minutes

nixCraft: Privacy First, Reader Supported
nixCraft is a one-person operation. I create all the content myself, with no help from AI or ML. I keep the content accurate and up-to-date.
Your privacy is my top priority. I don’t track you, show you ads, or spam you with emails. Just pure content in the true spirit of Linux and FLOSS.
Fast and clean browsing experience. nixCraft is designed to be fast and easy to use. You won’t have to deal with pop-ups, ads, cookie banners, or other distractions.
Support independent content creators. nixCraft is a labor of love, and it’s only possible thanks to the support of our readers. If you enjoy the content, please support us on Patreon or share this page on social media or your blog. Every bit helps.
Join Patreon ➔
How add or mount directory in LXD/LXC
The procedure to mount directories in LXD as follows:

Open the terminal application
For remote LXD/Linux server login using the ssh command
To mount the host’s /wwwdata/ directory onto /var/www/html/ in the LXD container named c1, run:

lxc config device add c1 sharedwww disk source=/wwwdata/ path=/var/www/html/
Verify that directory has been mounted onto c1 container by running:

lxc exec c1 -- "ls /var/www/html"
Let us see all steps in detail for mounting directories as both in read-only and read/write mode onto containers.

Mounting your home directory in LXD (read-only)
The syntax is as follows:
lxc config device add {container-name} {name} disk source={/path/to/source/dir/} path={/path/to/dest/onto/container/}

Let us create a new container named c1:
lxc launch images:centos/8/amd64 c1
lxc list c1

Create a new directory named /dest/ onto container named c1, run:
lxc exec c1 -- "mkdir /dest/"
lxc exec c1 -- "ls -ld /dest/"

Mount your $HOME (/home/vivek/) directory onto c1 at /dest/ in read only:
lxc config device add c1 myhomedir disk source=$HOME path=/dest/

OR
lxc config device add c1 myhomedir disk source=/home/vivek/ path=/dest/

Please note that if /dest/ directory does not exist, it will be created automatically by above lxc command. Now that disk added onto c1, verify it:
lxc config device show c1

Restart the container to verify that settings remain valid:
lxc restart c1
lxc config device show c1
## login onto c1 container ##
lxc exec c1 bash
cd /dest/
ls -l
## is it read-only or read-write? ##
mkdir foo
exit

Adding a shared host directory to an LXD Container
How to remove/delete/unmount directory from an LXD container
To remove container devices such as disk named myhomedir from c1 container, run:
lxc config device remove c1 myhomedir
Device myhomedir removed from c1

Verify it:
lxc config device show c1

Add a shared host directory to an LXC/LXD container (read-write mode)
By default, the root user is not allowed to modify files inside containers from a host. It is a security feature of LXD. In other words, you need to remap your user ID if you need read-write access for mounted folders.

The subordinate gid file
Each line in /etc/subgid contains a user name and a range of subordinate group ids that user is allowed to use. This file specifies the group IDs that ordinary users can use, with the newgidmap command, to configure gid mapping in a user namespace. This is specified with three fields delimited by colons (“:). Use the cat command:
cat /etc/subgid

Sample outputs:

vivek:100000:65536
Where fields are:

vivek – Login name or UID on host
100000 – Numerical subordinate group ID
65536 – Numerical subordinate group ID count
The subordinate uid file
Again, each line in /etc/subuid contains a user name and a range of subordinate user ids that user is allowed to use. This file specifies the user IDs that ordinary users can use, with the newuidmap command, to configure uid mapping in a user namespace. To view this file, run:
cat /etc/subuid

Sample outputs:

vivek:100000:65536
How to allow LXD to remap your user ID on the host
Use the id command to find out your uid/gid:
id

Sample outputs:

uid=1000(vivek) gid=1000(vivek) groups=1000(vivek),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),115(lpadmin),116(sambashare),998(lxd)
Next, I am going to allow the LXD demon which is running as root to remap my host’s user ID inside a container:
echo "root:1000:1" | sudo tee -a /etc/subuid /etc/subgid

This is a one time set up and no need to repeat. Make sure file has been updated:
cat /etc/{subuid,subgid}

How to remap your user ID inside the container
Find UID inside the container for the user named vivek (user account must exist inside the c1):
lxc exec c1 bash
grep command '^vivek' /etc/passwd

Create a user account named if no output displayed by above grep command:
lxc exec c1 bash
adduser vivek
id vivek
exit

Type the following command to map both the UID and the GID, from the host’s UID (1000) to the c1 container’s 1000 UID (vivek):
lxc config set c1 raw.idmap "both 1000 1000"

Restart the container to settings take effect:
lxc restart c1

Finally, mount and map the directory in a read/write mode:
lxc config device add c1 myhomedir disk source=/home/vivek/ path=/home/vivek/
lxc config show c1

Test it
lxc exec c1 bash
cd /home/vivek
mkdir delta
echo "www.nixcraft.com" > test.txt
cat test.txt
rmdir delta
## back to the host ##
exit
## make sure bar.txt still exists on host ##
ls -l test.txt
cat test.txt

Linux mount directory in LXD in read and write mode
Successfully mounted hosts /home/vivek/ directory onto c1 containers in read-write mode

Conclusion
You learned how to bind-mount your Linux home directory in LXD either in read-only or read-write mode by mapping UID/GID. This feature is handy to mount high availability storage into a container. See LXD project docs for more info.


----
TO READ
https://stgraber.org/
https://stgraber.org/2017/06/15/custom-user-mappings-in-lxd-containers/
https://ubuntu.com/blog/nested-containers-in-lxd
https://ubuntu.com/blog/network-management-with-lxd-2-3
https://ubuntu.com/blog/container-to-container-networking-the-bits-have-hit-the-fan
https://ubuntu.com/blog/live-migration-in-lxd
https://ubuntu.com/blog/on-the-road-to-lean-infrastructure
https://ubuntu.com/blog/usb-hotplug-with-lxd-containers
https://ubuntu.com/blog/maas-for-the-home

















-->


<!-- vim: set sw=4 sts=4 ai si et tw=79 ft=markdown: -->
