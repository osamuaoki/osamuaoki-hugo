---
title: Container with LXC/LXD (6)
date: 2023-11-30T00:00:00+00:00
categories:
  - desktop
  - english
tags:
  - lxc
draft: true
slug: lxc-6
---

Here is a series of memos of me trying to use LXC/LXD on Debian 12 (`bookworm`).

<!--
VMã®è©±ã€€1. [ãƒªãƒ¢ãƒ¼ãƒˆã®LXDã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ç”»é¢ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã‹ã‚‰æ“ä½œã—ã¦VDIç’°å¢ƒã‚’æ§‹ç¯‰ã™ã‚‹](https://gihyo.jp/admin/serial/01/ubuntu-recipe/0738) (2022-11-09)
XRDPåˆ©ç”¨ã§PROXY
  1. [é–‹ç™ºæ—¥èªŒï¼šLXD ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—RDP](https://note.com/koya0316/n/n4a0f6e095047) (2021-07-30)
  1. [LXD + Ubuntu 18.04 + MATE + xrdpã§ãƒªãƒ¢ãƒ¼ãƒˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç’°å¢ƒã‚’ä½œã‚‹](https://qiita.com/330k/items/3fc42431d4d08b925541) (2021-03-09)
-->

## LXD with xrdp




## YAML data example to set profile=wayland_pipewire

Let me address more IPC sockets etc., here.

```
 $ cat wayland_full.yaml
```

This updated YAML data is designed to connect IPC sockets not just for Wayland
but also X, PulseAudio and Pipewire.  Also, this has `raw.idmap` entry.





<!--

https://documentation.ubuntu.com/lxd/en/latest/userns-idmap/
Idmaps for user namespace
LXD runs safe containers. This is achieved mostly through the use of user namespaces which make it possible to run containers unprivileged, greatly limiting the attack surface.

User namespaces work by mapping a set of UIDs and GIDs on the host to a set of UIDs and GIDs in the container.

For example, we can define that the host UIDs and GIDs from 100000 to 165535 may be used by LXD and should be mapped to UID/GID 0 through 65535 in the container.

As a result a process running as UID 0 in the container will actually be running as UID 100000.

Allocations should always be of at least 65536 UIDs and GIDs to cover the POSIX range including root (0) and nobody (65534).

Kernel support
User namespaces require a kernel >= 3.12, LXD will start even on older kernels but will refuse to start containers.

Allowed ranges
On most hosts, LXD will check /etc/subuid and /etc/subgid for allocations for the lxd user and on first start, set the default profile to use the first 65536 UIDs and GIDs from that range.

If the range is shorter than 65536 (which includes no range at all), then LXD will fail to create or start any container until this is corrected.

If some but not all of /etc/subuid, /etc/subgid, newuidmap (path lookup) and newgidmap (path lookup) can be found on the system, LXD will fail the startup of any container until this is corrected as this shows a broken shadow setup.

If none of those files can be found, then LXD will assume a 1000000000 UID/GID range starting at a base UID/GID of 1000000.

This is the most common case and is usually the recommended setup when not running on a system which also hosts fully unprivileged containers (where the container runtime itself runs as a user).

Varying ranges between hosts
The source map is sent when moving containers between hosts so that they can be remapped on the receiving host.

Different idmaps per container
LXD supports using different idmaps per container, to further isolate containers from each other. This is controlled with two per-container configuration keys, security.idmap.isolated and security.idmap.size.

Containers with security.idmap.isolated will have a unique ID range computed for them among the other containers with security.idmap.isolated set (if none is available, setting this key will simply fail).

Containers with security.idmap.size set will have their ID range set to this size. Isolated containers without this property set default to a ID range of size 65536; this allows for POSIX compliance and a nobody user inside the container.

To select a specific map, the security.idmap.base key will let you override the auto-detection mechanism and tell LXD what host UID/GID you want to use as the base for the container.

These properties require a container reboot to take effect.

Custom idmaps
LXD also supports customizing bits of the idmap, e.g. to allow users to bind mount parts of the hostâ€™s file system into a container without the need for any UID-shifting file system. The per-container configuration key for this is raw.idmap, and looks like:

both 1000 1000
uid 50-60 500-510
gid 100000-110000 10000-20000
The first line configures both the UID and GID 1000 on the host to map to UID 1000 inside the container (this can be used for example to bind mount a userâ€™s home directory into a container).

The second and third lines map only the UID or GID ranges into the container, respectively. The second entry per line is the source ID, i.e. the ID on the host, and the third entry is the range inside the container. These ranges must be the same size.

This property requires a container reboot to take effect.

https://discuss.linuxcontainers.org/t/need-id-mapping-root-and-user-in-container-to-same-user-in-host/15461
Need ID mapping root and user in container to same user in host
...
This is not possible AFAIK. So what I did?

lxc config set t7 raw.idmap "both 1000 0"
This maps my user in the host (1000:1000) to the root user into the LXD container.

What did I get?: my docker containers running inside the LXD container can manage devices and resources as root, and they can access all the directory binds that I need (owned by user 1000:1000 in the host).


https://gihyo.jp/admin/serial/01/ubuntu-recipe/0479
ç¬¬479å›ž
LXDã‚³ãƒ³ãƒ†ãƒŠã¨ãƒ›ã‚¹ãƒˆã®é–“ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…±æœ‰ã™ã‚‹æ–¹æ³•


ãƒ›ã‚¹ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ¼ãƒ„ãƒªãƒ¼ã‚’bind mountã™ã‚‹
åå‰ç©ºé–“ã«ã‚ˆã‚‹åˆ¶é™ã«ã‚ˆã‚Šã€ã‚³ãƒ³ãƒ†ãƒŠã‹ã‚‰ãƒ›ã‚¹ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚’ç›´æŽ¥è¦‹ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚ã¾ãŸAppArmorã«ã‚ˆã‚Šã€ã‚³ãƒ³ãƒ†ãƒŠå†…éƒ¨ã‹ã‚‰ã®ãƒ–ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã®mountã¯ç¦æ­¢ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚‚ã—ã‚³ãƒ³ãƒ†ãƒŠã¨ãƒ›ã‚¹ãƒˆã®é–“ã€ã‚‚ã—ãã¯åŒã˜ãƒ›ã‚¹ãƒˆä¸Šã®ã‚³ãƒ³ãƒ†ãƒŠé–“ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…±æœ‰ã—ãŸã„å ´åˆã¯ã€ã‚³ãƒ³ãƒ†ãƒŠã®è¨­å®šã§bind mountã™ã‚‹æ–¹æ³•ãŒä¾¿åˆ©ã§ã™ã€‚

$ lxc config device add sample share disk source=/srv/shared path=/srv/shared
ä¸Šè¨˜ã®ã‚³ãƒžãƒ³ãƒ‰ã¯ãƒ›ã‚¹ãƒˆã®/srv/sharedï¼ˆsource=ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã‚’ã€ã‚³ãƒ³ãƒ†ãƒŠå†…éƒ¨ã®/srv/sharedï¼ˆpath=ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã¨ã—ã¦bind mountã—ã¾ã™ã€‚ã¤ã¾ã‚Šãƒ›ã‚¹ãƒˆã¨ã‚³ãƒ³ãƒ†ãƒŠã§/srv/sharedã‚’å…±æœ‰ã§ãã‚‹ã¨ã„ã†ã‚ã‘ã§ã™ã€‚

lxc configã«ã‚ˆã‚‹è¨­å®šã¯æ°¸ç¶šçš„ã«åæ˜ ã•ã‚Œã¾ã™ã®ã§ã€ã‚³ãƒ³ãƒ†ãƒŠã®å†èµ·å‹•ã‚’è¡Œã£ã¦ã‚‚ãã®ã¾ã¾æ®‹ã£ã¦ã„ã¾ã™ã€‚

$ lxc config show sample
ï¼ˆä¸­ç•¥ï¼‰
devices:
  nfsdir:
    path: /srv/shared
    source: /srv/shared
    type: disk
ï¼ˆå¾Œç•¥ï¼‰
ã“ã®æ–¹æ³•ã®ãƒ¡ãƒªãƒƒãƒˆã¯ã€ãƒ›ã‚¹ãƒˆå´ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã«é–¢ä¿‚ãªãåŒã˜æ–¹æ³•ã§ã‚³ãƒ³ãƒ†ãƒŠã¨å…±æœ‰ã§ãã‚‹ã“ã¨ã§ã™ã€‚ãŸã¨ãˆã°ã‚³ãƒ³ãƒ†ãƒŠã®å†…éƒ¨ã‹ã‚‰NFSãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’mountã™ã‚‹å ´åˆã‚‚ã€ä¸€åº¦ãƒ›ã‚¹ãƒˆå´ã§NFSãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’mountã—ã¦ãŠã‘ã°ã€ãã‚Œã‚’ãã®ã¾ã¾ã‚³ãƒ³ãƒ†ãƒŠã«bind mountã§ãã‚‹ã®ã§ã™ã€‚ã‚ˆã£ã¦åŒã˜ãƒ›ã‚¹ãƒˆä¸Šã®ã‚³ãƒ³ãƒ†ãƒŠé–“ã ã‘ã§ãªãã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¶Šã—ã®ã‚³ãƒ³ãƒ†ãƒŠé–“ã¨ã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å…±æœ‰ã§ãã¾ã™ã€‚

ãŸã ã—lxc fileã¨ç•°ãªã‚Šã€UIDç­‰ã®ãƒžãƒƒãƒ”ãƒ³ã‚°ã®å¤‰æ›´ã¯è¡Œã„ã¾ã›ã‚“ã€‚ã‚ˆã£ã¦ã‚³ãƒ³ãƒ†ãƒŠã®ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ä½œã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚ªãƒ¼ãƒŠãƒ¼ã¯ã€ãƒ›ã‚¹ãƒˆã‹ã‚‰è¦‹ã‚‹ã¨ã¨ã¦ã‚‚å¤§ããªUIDã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ã€‚

ãƒ›ã‚¹ãƒˆã¨ã‚³ãƒ³ãƒ†ãƒŠã§UIDç­‰ã‚’ä¸€è‡´ã•ã›ã‚‹
bind mountã«ã‚ˆã‚‹å…±æœ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ã†å ´åˆã€ãƒ›ã‚¹ãƒˆã¨ã‚³ãƒ³ãƒ†ãƒŠã§ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®UIDç­‰ã‚’ä¸€è‡´ã•ã›ãŸã»ã†ãŒä¾¿åˆ©ã§ã™ã€‚ã¤ã¾ã‚Šã‚³ãƒ³ãƒ†ãƒŠã®UID=1000ã¯ãƒ›ã‚¹ãƒˆã§ã‚‚UID=1000ã«ã—ã¾ã™ã€‚ã‚‚ã¡ã‚ã‚“rootã‚’ä¸€è‡´ã•ã›ã‚‹ã¨ãã‚Œã¯ã¨ã©ã®ã¤ã¾ã‚Šã€Œã»ã¼ç‰¹æ¨©ã‚³ãƒ³ãƒ†ãƒŠã€ã¨ãªã‚Šã¾ã™ã®ã§ã€éžç‰¹æ¨©ã‚³ãƒ³ãƒ†ãƒŠã«ã—ã¦ãŠãæ„å‘³ãŒè–„ã‚Œã¾ã™ã€‚ã‚ãã¾ã§ã€Œæ™®æ®µä½¿ã†ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ã®ã¿UIDã‚’ä¸€è‡´ã•ã›ã‚‹ã®ã§ã™ã€‚ç†æƒ³çš„ã«ã¯ãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯sudoã‚°ãƒ«ãƒ¼ãƒ—ã«å…¥ã£ã¦ã„ãªã„ã»ã†ãŒã„ã„ã§ã—ã‚‡ã†ã€‚
gg
UIDç­‰ã®ãƒžãƒƒãƒ”ãƒ³ã‚°ã¯/etc/subuidã€/etc/subgidãƒ•ã‚¡ã‚¤ãƒ«ã§ç®¡ç†ã—ã¦ã„ã¾ã™ã€‚UID=1000ã€GID=1000ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚°ãƒ«ãƒ¼ãƒ—ã¯ãƒ›ã‚¹ãƒˆã¨ã‚³ãƒ³ãƒ†ãƒŠã§ä¸€è‡´ã—ãŸã„å ´åˆã¯æ¬¡ã®ã‚ˆã†ã«è¨­å®šã—ã¾ã™ã€‚

$ echo "root:1000:1" | sudo tee -a /etc/subuid
$ echo "root:1000:1" | sudo tee -a /etc/subgid
ã“ã®ã†ã¡rootã¯ä»Šå›žè¨­å®šã—ãŸUIDç­‰ã®ãƒžãƒƒãƒ”ãƒ³ã‚°ã‚’è¨±å¯ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã™ã€‚LXDã®å ´åˆã¯rootãŒã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•æ™‚ã«ãƒžãƒƒãƒ”ãƒ³ã‚°ã‚’è¡Œã†ã®ã§rootã«ã—ã¦ã„ã¾ã™ã€‚æ›¸å¼ã¯ã€ŒUSER:START:COUNTã€ã§ã™ã€‚ä¸Šè¨˜è¨­å®šã®å ´åˆã¯ã€ã€Œâ ID=1000ã‹ã‚‰1ã¤ã€ã«ãªã‚Šã¾ã™ã€‚ã‚‚ã¡ã‚ã‚“ã€Œ1ã€ã‚’ã€Œ100ã€ã«ã—ã¦è¤‡æ•°ã®UIDã‚’ãƒžãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚

ã‚³ãƒ³ãƒ†ãƒŠå†…éƒ¨ã®ãƒžãƒƒãƒ”ãƒ³ã‚°ã«é–¢ã™ã‚‹è¨­å®šã¯ã€ã‚³ãƒ³ãƒ†ãƒŠã”ã¨ã«è¡Œã„ã¾ã™ã€‚

$ lxc config set sample raw.idmap 'both 1000 1000'
ã€Œbothã€ã¯UIDã¨GIDä¸¡æ–¹ã«åŒã˜å€¤ã‚’è¨­å®šã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚æ›¸å¼ã¯ã€Œboth HOST_ID CONTAINER_IDã€ã¨ãªã‚Šã¾ã™ã€‚HOST_IDã«ã¯ãƒ›ã‚¹ãƒˆä¸Šã®UID/GIDã‚’ã€CONTAINER_IDã«ã¯HOST_IDã‚’ã‚³ãƒ³ãƒ†ãƒŠã®ä¸­ã«ãƒžãƒƒãƒ—ã—ãŸæ™‚ã®IDã‚’è¨˜è¿°ã—ã¾ã™ã€‚è¨€ã„æ›ãˆã‚‹ã¨ã€Œãƒ›ã‚¹ãƒˆä¸Šã®UID/GID 1000ã‚’ã‚³ãƒ³ãƒ†ãƒŠä¸Šã®UID/GID 1000ã¨ã—ã¦æ‰±ã†ã€ã¨ã„ã†ã“ã¨ã§ã™ã€‚

ã‚‚ã—UID/GIDã‚’ç•°ãªã‚‹å€¤ã«ã—ãŸã„å ´åˆã¯bothã®ã‹ã‚ã‚Šã«uidã‚„gidã‚’ä½¿ã„ã¾ã™ã€‚

ãƒ›ã‚¹ãƒˆä¸Šã®UID=1010ã‚’ã‚³ãƒ³ãƒ†ãƒŠä¸Šã§ã¯UID=1000ã¨ã—ã¦æ‰±ã„ãŸã„å ´åˆ
uid 1010 1000

ãƒ›ã‚¹ãƒˆä¸Šã®GID=1011ã‚’ã‚³ãƒ³ãƒ†ãƒŠä¸Šã§ã¯GID=1000ã¨ã—ã¦æ‰±ã„ãŸã„å ´åˆ
gid 1011 1000
uidã¨gidã‚’åŒæ™‚ã«è¨­å®šã—ãŸã„å ´åˆã¯ã€æ”¹è¡Œã§ã¤ãªãŽã¾ã™ã€‚ã—ã‹ã—ãªãŒã‚‰lxc configã‚³ãƒžãƒ³ãƒ‰ã¯ç›´æŽ¥æ”¹è¡Œã‚’æ‰±ãˆã¾ã›ã‚“ã€‚ãã“ã§è¨­å®šå†…å®¹ã‚’æ¨™æº–å…¥åŠ›ã‹ã‚‰å—ã‘ä»˜ã‘ã‚‹ã‚ˆã†ã«ã—ã¦ã€ãã“ã«ãƒ‘ã‚¤ãƒ—ã§è¨­å®šå†…å®¹ã‚’æµã—è¾¼ã¿ã¾ã™ã€‚

$ echo -e "uid 1010 1000\ngid 1011 1000" | lxc config set xenial raw.idmap -
ãƒã‚¤ãƒ•ãƒ³ã‚’ã¤ãªã„ã§ç¯„å›²ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚ã“ã®å ´åˆã€ãƒžãƒƒãƒ”ãƒ³ã‚°å…ƒã¨ãƒžãƒƒãƒ”ãƒ³ã‚°å…ˆã®å€‹æ•°ãŒåŒã˜ã«ãªã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

å¤‰æ›´ã—ãŸè¨­å®šã‚’åæ˜ ã™ã‚‹ã«ã¯ã€ä¸€åº¦ãã®ã‚³ãƒ³ãƒ†ãƒŠã‚’å†èµ·å‹•ã—ã¾ã™ã€‚å†’é ­ã¨åŒã˜ã‚ˆã†ã«ãƒ—ãƒ­ã‚»ã‚¹ã®UIDã‚’ã‚³ãƒ³ãƒ†ãƒŠã¨ãƒ›ã‚¹ãƒˆã§æ¯”ã¹ãŸã‚‰ã€UID=0ã¯ãƒžãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã®ã€UID=1000ã¯ã‚³ãƒ³ãƒ†ãƒŠã¨ãƒ›ã‚¹ãƒˆã§ä¸€è‡´ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã¯ãšã§ã™ã€‚

ã“ã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã‚Œã°ã€ãƒ›ã‚¹ãƒˆãƒ»ã‚³ãƒ³ãƒ†ãƒŠé–“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©ã‚’ãã‚Œãªã‚Šã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ã“ã¨ã§ã—ã‚‡ã†ã€‚
---------------
https://stgraber.org/2017/06/15/custom-user-mappings-in-lxd-containers/
Introduction
As you may know, LXD uses unprivileged containers by default.
The difference between an unprivileged container and a privileged one is whether the root user in the container is the â€œrealâ€ root user (uid 0 at the kernel level).

The way unprivileged containers are created is by taking a set of normal UIDs and GIDs from the host, usually at least 65536 of each (to be POSIX compliant) and mapping those into the container.

The most common example and what most LXD users will end up with by default is a map of 65536 UIDs and GIDs, with a host base id of 100000. This means that root in the container (uid 0) will be mapped to the host uid 100000 and uid 65535 in the container will be mapped to uid 165535 on the host. UID/GID 65536 and higher in the container arenâ€™t mapped and will return an error if you attempt to use them.

From a security point of view, that means that anything which is not owned by the users and groups mapped into the container will be inaccessible. Any such resource will show up as being owned by uid/gid â€œ-1â€ (rendered as 65534 or nobody/nogroup in userspace). It also means that should there be a way to escape the container, even root in the container would find itself with just as much privileges on the host as a nobody user.

LXD does offer a number of options related to unprivileged configuration:

Increasing the size of the default uid/gid map
Setting up per-container maps
Punching holes into the map to expose host users and groups
Increasing the size of the default map
As mentioned above, in most cases, LXD will have a default map thatâ€™s made of 65536 uids/gids.

In most cases you wonâ€™t have to change that. There are however a few cases where you may have to:

You need access to uid/gid higher than 65535.
This is most common when using network authentication inside of your containers.
You want to use per-container maps.
In which case youâ€™ll need 65536 available uid/gid per container.
You want to punch some holes in your containerâ€™s map and need access to host uids/gids.
The default map is usually controlled by the â€œshadowâ€ set of utilities and files. On systems where thatâ€™s the case, the â€œ/etc/subuidâ€ and â€œ/etc/subgidâ€ files are used to configure those maps.

On systems that do not have a recent enough version of the â€œshadowâ€ package. LXD will assume that it doesnâ€™t have to share uid/gid ranges with anything else and will therefore assume control of a billion uids and gids, starting at the host uid/gid 100000.

But the common case, is a system with a recent version of shadow.
An example of what the configuration may look like is:

stgraber@castiana:~$ cat /etc/subuid
lxd:100000:65536
root:100000:65536

stgraber@castiana:~$ cat /etc/subgid
lxd:100000:65536
root:100000:65536
The maps for â€œlxdâ€ and â€œrootâ€ should always be kept in sync. LXD itself is restricted by the â€œrootâ€ allocation. The â€œlxdâ€ entry is used to track what needs to be removed if LXD is uninstalled.

Now if you want to increase the size of the map available to LXD. Simply edit both of the files and bump the last value from 65536 to whatever size you need. I tend to bump it to a billion just so I donâ€™t ever have to think about it again:

stgraber@castiana:~$ cat /etc/subuid
lxd:100000:1000000000
root:100000:1000000000

stgraber@castiana:~$ cat /etc/subgid
lxd:100000:1000000000
root:100000:100000000
After altering those files, you need to restart LXD to have it detect the new map:

root@vorash:~# systemctl restart lxd
root@vorash:~# cat /var/log/lxd/lxd.log
lvl=info msg="LXD 2.14 is starting in normal mode" path=/var/lib/lxd t=2017-06-14T21:21:13+0000
lvl=warn msg="CGroup memory swap accounting is disabled, swap limits will be ignored." t=2017-06-14T21:21:13+0000
lvl=info msg="Kernel uid/gid map:" t=2017-06-14T21:21:13+0000
lvl=info msg=" - u 0 0 4294967295" t=2017-06-14T21:21:13+0000
lvl=info msg=" - g 0 0 4294967295" t=2017-06-14T21:21:13+0000
lvl=info msg="Configured LXD uid/gid map:" t=2017-06-14T21:21:13+0000
lvl=info msg=" - u 0 1000000 1000000000" t=2017-06-14T21:21:13+0000
lvl=info msg=" - g 0 1000000 1000000000" t=2017-06-14T21:21:13+0000
lvl=info msg="Connecting to a remote simplestreams server" t=2017-06-14T21:21:13+0000
lvl=info msg="Expiring log files" t=2017-06-14T21:21:13+0000
lvl=info msg="Done expiring log files" t=2017-06-14T21:21:13+0000
lvl=info msg="Starting /dev/lxd handler" t=2017-06-14T21:21:13+0000
lvl=info msg="LXD is socket activated" t=2017-06-14T21:21:13+0000
lvl=info msg="REST API daemon:" t=2017-06-14T21:21:13+0000
lvl=info msg=" - binding Unix socket" socket=/var/lib/lxd/unix.socket t=2017-06-14T21:21:13+0000
lvl=info msg=" - binding TCP socket" socket=[::]:8443 t=2017-06-14T21:21:13+0000
lvl=info msg="Pruning expired images" t=2017-06-14T21:21:13+0000
lvl=info msg="Updating images" t=2017-06-14T21:21:13+0000
lvl=info msg="Done pruning expired images" t=2017-06-14T21:21:13+0000
lvl=info msg="Done updating images" t=2017-06-14T21:21:13+0000
root@vorash:~#
As you can see, the configured map is logged at LXD startup and can be used to confirm that the reconfiguration worked as expected.

Youâ€™ll then need to restart your containers to have them start using your newly expanded map.

Per container maps
Provided that you have a sufficient amount of uid/gid allocated to LXD, you can configure your containers to use their own, non-overlapping allocation of uids and gids.

This can be useful for two reasons:

You are running software which alters kernel resource ulimits.
Those user-specific limits are tied to a kernel uid and will cross container boundaries leading to hard to debug issues where one container can perform an action but all others are then unable to do the same.
You want to know that should there be a way for someone in one of your containers to somehow get access to the host that they still wonâ€™t be able to access or interact with any of the other containers.
The main downsides to using this feature are:

Itâ€™s somewhat wasteful with using 65536 uids and gids per container.
That being said, youâ€™d still be able to run over 60000 isolated containers before running out of system uids and gids.
Itâ€™s effectively impossible to share storage between two isolated containers as everything written by one will be seen as -1 by the other. There is ongoing work around virtual filesystems in the kernel that will eventually let us get rid of that limitation.
To have a container use its own distinct map, simply run:

stgraber@castiana:~$ lxc config set test security.idmap.isolated true
stgraber@castiana:~$ lxc restart test
stgraber@castiana:~$ lxc config get test volatile.last_state.idmap
[{"Isuid":true,"Isgid":false,"Hostid":165536,"Nsid":0,"Maprange":65536},{"Isuid":false,"Isgid":true,"Hostid":165536,"Nsid":0,"Maprange":65536}]
The restart step is needed to have LXD remap the entire filesystem of the container to its new map.
Note that this step will take a varying amount of time depending on the number of files in the container and the speed of your storage.

As can be seen above, after restart, the container is shown to have its own map of 65536 uids/gids.

If you want LXD to allocate more than the default 65536 uids/gids to an isolated container, you can bump the size of the allocation with:

stgraber@castiana:~$ lxc config set test security.idmap.size 200000
stgraber@castiana:~$ lxc restart test
stgraber@castiana:~$ lxc config get test volatile.last_state.idmap
[{"Isuid":true,"Isgid":false,"Hostid":165536,"Nsid":0,"Maprange":200000},{"Isuid":false,"Isgid":true,"Hostid":165536,"Nsid":0,"Maprange":200000}]
If youâ€™re trying to allocate more uids/gids than are left in LXDâ€™s allocation, LXD will let you know:

stgraber@castiana:~$ lxc config set test security.idmap.size 2000000000
error: Not enough uid/gid available for the container.
Direct user/group mapping
The fact that all uids/gids in an unprivileged container are mapped to a normally unused range on the host means that sharing of data between host and container is effectively impossible.

Now, what if you want to share your userâ€™s home directory with a container?

The obvious answer to that is to define a new â€œdiskâ€ entry in LXD which passes your home directory to the container:

stgraber@castiana:~$ lxc config device add test home disk source=/home/stgraber path=/home/ubuntu
Device home added to test
So that was pretty easy, but did it work?

stgraber@castiana:~$ lxc exec test -- bash
root@test:~# ls -lh /home/
total 529K
drwx--x--x 45 nobody nogroup 84 Jun 14 20:06 ubuntu
No. The mount is clearly there, but itâ€™s completely inaccessible to the container.
To fix that, we need to take a few extra steps:

Allow LXDâ€™s use of our user uid and gid
Restart LXD to have it load the new map
Set a custom map for our container
Restart the container to have the new map apply
stgraber@castiana:~$ printf "lxd:$(id -u):1\nroot:$(id -u):1\n" | sudo tee -a /etc/subuid
lxd:201105:1
root:201105:1

stgraber@castiana:~$ printf "lxd:$(id -g):1\nroot:$(id -g):1\n" | sudo tee -a /etc/subgid
lxd:200512:1
root:200512:1

stgraber@castiana:~$ sudo systemctl restart lxd

stgraber@castiana:~$ printf "uid $(id -u) 1000\ngid $(id -g) 1000" | lxc config set test raw.idmap -

stgraber@castiana:~$ lxc restart test
At which point, things should be working in the container:

stgraber@castiana:~$ lxc exec test -- su ubuntu -l
ubuntu@test:~$ ls -lh
total 119K
drwxr-xr-x 5  ubuntu ubuntu 8 Feb 18 2016 data
drwxr-x--- 4  ubuntu ubuntu 6 Jun 13 17:05 Desktop
drwxr-xr-x 3  ubuntu ubuntu 28 Jun 13 20:09 Downloads
drwx------ 84 ubuntu ubuntu 84 Sep 14 2016 Maildir
drwxr-xr-x 4  ubuntu ubuntu 4 May 20 15:38 snap
ubuntu@test:~$

Conclusion
User namespaces, the kernel feature that makes those uid/gid mappings possible is a very powerful tool which finally made containers on Linux safe by design. It is however not the easiest thing to wrap your head around and all of that uid/gid map math can quickly become a major issue.

In LXD weâ€™ve tried to expose just enough of those underlying features to be useful to our users while doing the actual mapping math internally. This makes things like the direct user/group mapping above significantly easier than it otherwise would be.

Going forward, weâ€™re very interested in some of the work around uid/gid remapping at the filesystem level, this would let us decouple the on-disk user/group map from that used for processes, making it possible to share data between differently mapped containers and alter the various maps without needing to also remap the entire filesystem.

Extra information
The main LXD website is at: https://linuxcontainers.org/lxd
Development happens on Github at: https://github.com/lxc/lxd
Discussion forun: https://discuss.linuxcontainers.org
Mailing-list support happens on: https://lists.linuxcontainers.org
IRC support happens in: #lxcontainers on irc.freenode.net
Try LXD online: https://linuxcontainers.org/lxd/try-it


----
https://stackoverflow.com/questions/71738168/linux-container-failed-to-set-up-id-mapping


your mappings look quite wrong... syntax should be :

/etc/subuid

[local unprivileged user on the host that will run the container]:[uid on the host start at(this is inexisting uid on the host and it is ok)]:[number/range of uid to map]

e.g : toto:100000:65535

/etc/subuid

[local unprivileged group on the host that will run the container]:[guid on the host start at(this is inexisting gid on the host and it is ok)]:[number/range of uid to map]

e.g : toto:100000:65535

config

then, in the config file of the container, if you want to restrict the access further, you can do some specific mappings:

lxc.idmap = u 0 100000 1

lxc.idmap = g 0 100000 1

lxc.idmap = u 33 100033 1

lxc.idmap = g 33 100033 1

will map the uid and gid 0 (root) in the container to uid and gid 100000 on the host

will map the uid and gid 33 (www-data) in the container to uid and gid 100033 on the host

--------------

LXDã®ã‚³ãƒ³ãƒ†ãƒŠä¸­ã§ãƒ›ã‚¹ãƒˆã®ãƒ›ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’èª­ã¿æ›¸ãã™ã‚‹æ–¹æ³•
https://qiita.com/m-shibata/items/2969ab84bab9235d25f0
https://ubuntu.com/blog/mounting-your-home-directory-in-lxd
Mounting your home directory in LXD
As of LXD stable 2.0.8 and feature release 2.6, LXD has support for various UID and GID map related manipulaions. A common question is: â€œHow do I bind-mount my home directory into a container?â€ and before the answer was â€œwell, itâ€™s complicated but you can do it; itâ€™s slightly less complicated if you do it in privleged containersâ€. However, with this feature, now you can do it very easily in unprivileged containers.

First, find out your uid on the host:

$ id
uid=1000(tycho) gid=1000(tycho) groups=1000(tycho),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),112(lpadmin),124(sambashare),129(libvirtd),149(lxd),150(sbuild)
On standard Ubuntu hosts, the uid of the first user is 1000. Now, we need to allow LXD to remap to remap this id; youâ€™ll need an additional entry for root to do this:

$ echo 'root:1000:1' | sudo tee -a /etc/subuid /etc/subgid
Now, create a container, and set the idmap up to map both uid and gid 1000 to uid and gid 1000 inside the container.

$ lxc init ubuntu-daily:z zesty
Creating zesty

$ lxc config set zesty raw.idmap 'both 1000 1000'
Finally, set up your home directory to be mounted in the container:

$ lxc config device add zesty homedir disk source=/home/tycho path=/home/ubuntu
And leave an insightful message for users of the container:

$ echo 'meshuggah rocks' >> message
Finally, start your container and read the message:

$ lxc start zesty
$ lxc exec zesty cat /home/ubuntu/message
meshuggah rocks
And enjoy the insight offered to you by your home directory ðŸ™‚


Sunday, August 28, 2022
LXD Containers for Wayland GUI Apps
https://blog.swwomm.com/2022/08/lxd-containers-for-wayland-gui-apps.html

---
Install any OS via ISO in a Virtual machine/VM
https://discuss.linuxcontainers.org/t/install-any-os-via-iso-in-a-virtual-machine-vm/9281
Windows VM:
Take a look at: Running virtual machines with LXD 4.0 147
or:
How to run a Windows virtual machine on LXD on Linux 141

Linux VM:

Start an empty VM with:
Note: Change VM-name to a custom name you choose.

lxc init VM-name --empty --vm

Note: In some cases it might be required to disable SecureBoot, when it blocks the .iso file (Recommendation: Disable only when necessary!).
You can do this, either by adding -c security.secureboot=false to the init/launch command
or by modifying the config key of an existing VM with: lxc config set VM-name security.secureboot=false.

Grow the VMs filesystem size:
The default size is mostly too small.
You can choose what size you think is reasonable, in this example I use 15 Gigabyte (GB).

lxc config device override VM-name root size=15GB

Add the .iso file to the VM via a disk device:
Note: Adjust the values accordingly.

lxc config device add VM-name custom-device-name disk source=/home/user/pathtoiso/isoname.iso

Start the VM with GUI:
lxc start VM-name --console=vga

--console=vga will open a VGA console.

(Note: You maybe need to install additional software for this, see GUI in Virtual Machines/VMs)

Remove disk device:
After installation you can remove the disk device, with:
lxc config device remove VM-name device-name

(optional) Convert your VM to an image:
So you can use it in the future.

lxc publish VM-name --alias custom-image-name


-----------
https://ubuntu.com/tutorials/how-to-launch-an-instantly-functional-linux-desktop-vm-with-lxd#2-initiate-an-ubuntu-desktop-vm
How to launch an instantly functional Linux desktop VM with LXD

The full command for launching an Ubuntu 22.04 VM would then look like this:

lxc launch images:ubuntu/22.04/desktop ubuntu --vm -c limits.cpu=4 -c limits.memory=4GiB --console=vga


Launching an Archlinux Desktop VM is similar to what weâ€™ve done previously with Ubuntu, with a single addition - disabling secure boot.

The full command for launching an Archlinux VM would then look like this:

lxc launch images:archlinux/desktop-gnome archlinux --vm -c security.secureboot=false -c limits.cpu=4 -c limits.memory=4GiB --console=vga



----------

How to run Docker inside LXD containers
https://ubuntu.com/tutorials/how-to-run-docker-inside-lxd-containers#1-overview

Btrfs is one of the storage pools Docker supports natively, so we should create a new btrfs storage pool and we will call it â€œdockerâ€:

lxc storage create docker btrfs

Now we can create a new LXD instance and call it â€œdemoâ€:

lxc launch images:ubuntu/20.04 demo

We can proceed and create a new storage volume on the â€œdockerâ€ storage pool created earlier:

lxc storage volume create docker demo

We will attach it to the â€œdemoâ€ container and call the device being added as â€œdockerâ€. Source volume is â€œdemoâ€ we created earlier, and we want that volume to be used for /var/lib/docker:

lxc config device add demo docker disk pool=docker source=demo path=/var/lib/docker

We need to add additional configuration so that Docker works well inside the container.

First we should allow nested containers required for Docker. Then, there are two additional security options needed - to intercept and emulate system calls. This normally wouldnâ€™t be allowed inside LXD default unprivileged containers, but Docker relies on it for its layers, so it is okay to enable it.

lxc config set demo security.nesting=true security.syscalls.intercept.mknod=true security.syscalls.intercept.setxattr=true

To apply these changes, we need to restart the instance:

lxc restart demo




3. Install Docker
To install Docker, we start by going inside the container:

lxc exec demo bash

Now we can follow the normal Docker installation instructions. Paste the following command:

sudo apt-get update

 sudo apt-get install \
 ca-certificates \
 curl \
 gnupg \
  lsb-release
Now we need to add Dockerâ€™s official GPG key:

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg \
--dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
And now we can install the Docker repository:

echo \
"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
Finally, we can install Docker itself:

sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io


4. Test your Docker container
Now we have Docker up and running. Letâ€™s test it by running an Ubuntu Docker container:

docker run -it ubuntu bash

And we can run the following to check that the processes are running correctly:

ps aux

And thatâ€™s it! Now you have a working Ubuntu Docker container inside of an LXD container. You can use it, or you can spin up another Docker image and proceed to use it according to your needs.

5. Additional information
Vast majority of Docker images will run fine inside LXD containers. However, few might not run properly. The reason for this is that LXD runs all its container unprivileged by default, which limits some of the actions of the user. Docker, on the other hand, runs privileged containers, and some actions might expect more privileges than LXD gives them, causing potential failures. For example, if youâ€™re running something inside a docker container that expects to run as root, it wonâ€™t be able to do actions as a real root user but rather only as root inside of the LXD container, which is more constrained.

-----
https://ubuntu.com/blog/howto-automatically-import-your-public-ssh-keys-into-lxd-instances
Just another reason why LXD is so awesomeâ€¦

You can easily configure your own cloud-init configuration into your LXD instance profile.

In my case, I want cloud-init to automatically ssh-import-id kirkland, to fetch my keys from Launchpad.  Alternatively, I could use gh:dustinkirkland to fetch my keys from Github.

Hereâ€™s how!

First, edit your default LXD profile (or any other, for that matter):

$ lxc profile edit default
Then, add the config snippet, like this:

config:
  user.vendor-data: |
    #cloud-config
    users:
      - name: root
        ssh-import-id: gh:dustinkirkland
        shell: /bin/bash
description: Default LXD profile
devices:
  eth0:
    name: eth0
    nictype: bridged
    parent: lxdbr0
    type: nic
name: default
Save and quit in your interactive editor, and then launch a new instance:

$ lxc launch ubuntu:x
Creating amazed-manatee
Starting amazed-manatee
Find your instanceâ€™s IP address:

$ lxc list
+----------------+---------+----------------------+----------------------------------------------+------------+-----------+
|      NAME      |  STATE  |         IPV4         |                     IPV6                     |    TYPE    | SNAPSHOTS |
+----------------+---------+----------------------+----------------------------------------------+------------+-----------+
| amazed-manatee | RUNNING | 10.163.22.135 (eth0) | fdce:be5e:b787:f7d2:216:3eff:fe1c:773 (eth0) | PERSISTENT | 0         |
+----------------+---------+----------------------+----------------------------------------------+------------+-----------+
And now SSH in!

$ ssh ubuntu@10.163.22.135
$ ssh -6 ubuntu@fdce:be5e:b787:f7d2:216:3eff:fe1c:773
Enjoy!

:-Dustin

---------
https://ubuntu.com/blog/publishing-lxd-images
While some work remains to be done for â€˜lxc publishâ€™, the current support is sufficient to show a full cycle of image workload with lxd.

Ubuntu Wily comes with systemd by default. Sometimes you might need a Wily container with upstart. And to repeatedly reproduce some tests on Wily with upstart, you might want to create a container image.

# lxc remote add lxc images.linuxcontainers.org
# lxc launch lxc:ubuntu/wily/amd64 w1
# lxc exec w1 -- apt-get -y install upstart-bin upstart-sysv
# lxc stop w1
# lxc publish --public w1 --alias=wily-with-upstart
# lxc image copy wily-with-upstart remote:  # optional
Now you can start a new container using

# lxc launch wily-with-upstart w-test-1
# lxc exec w-test-1 -- ls -alh /sbin/init
lrwxrwxrwx 1 root root 7 May 18 10:20 /sbin/init -> upstart
# lxc exec w-test-1 run-my-tests

-------
https://www.cyberciti.biz/faq/how-to-add-or-mount-directory-in-lxd-linux-container/
How to add or mount directory in LXD (Linux container)
Author: Vivek Gite Last updated: September 18, 2023 9 comments
See all LXD related Howtos/TutorialsIhave two LXD containers running. One is for Nginx, and another is for processing data. I need to share data between two containers. How do I add or mount a shared directory between two?

One can manage devices of running containers using lxc command. To add devices such as directory to containers, use lxc config device add command. This page explains how to add a host directory to an LXD container
Tutorial details
Difficulty level	Intermediate
Root privileges	Yes
Requirements	Linux terminal
Category	LXD
Prerequisites	LXD
OS compatibility	Alma â€¢ Alpine â€¢ Arch â€¢ Debian â€¢ Fedora â€¢ Linux â€¢ Mint â€¢ openSUSE â€¢ Pop!_OS â€¢ RHEL â€¢ Rocky â€¢ Stream â€¢ SUSE â€¢ Ubuntu
Est. reading time	4 minutes

nixCraft: Privacy First, Reader Supported
nixCraft is a one-person operation. I create all the content myself, with no help from AI or ML. I keep the content accurate and up-to-date.
Your privacy is my top priority. I donâ€™t track you, show you ads, or spam you with emails. Just pure content in the true spirit of Linux and FLOSS.
Fast and clean browsing experience. nixCraft is designed to be fast and easy to use. You wonâ€™t have to deal with pop-ups, ads, cookie banners, or other distractions.
Support independent content creators. nixCraft is a labor of love, and itâ€™s only possible thanks to the support of our readers. If you enjoy the content, please support us on Patreon or share this page on social media or your blog. Every bit helps.
Join Patreon âž”
How add or mount directory in LXD/LXC
The procedure to mount directories in LXD as follows:

Open the terminal application
For remote LXD/Linux server login using the ssh command
To mount the hostâ€™s /wwwdata/ directory onto /var/www/html/ in the LXD container named c1, run:

lxc config device add c1 sharedwww disk source=/wwwdata/ path=/var/www/html/
Verify that directory has been mounted onto c1 container by running:

lxc exec c1 -- "ls /var/www/html"
Let us see all steps in detail for mounting directories as both in read-only and read/write mode onto containers.

Mounting your home directory in LXD (read-only)
The syntax is as follows:
lxc config device add {container-name} {name} disk source={/path/to/source/dir/} path={/path/to/dest/onto/container/}

Let us create a new container named c1:
lxc launch images:centos/8/amd64 c1
lxc list c1

Create a new directory named /dest/ onto container named c1, run:
lxc exec c1 -- "mkdir /dest/"
lxc exec c1 -- "ls -ld /dest/"

Mount your $HOME (/home/vivek/) directory onto c1 at /dest/ in read only:
lxc config device add c1 myhomedir disk source=$HOME path=/dest/

OR
lxc config device add c1 myhomedir disk source=/home/vivek/ path=/dest/

Please note that if /dest/ directory does not exist, it will be created automatically by above lxc command. Now that disk added onto c1, verify it:
lxc config device show c1

Restart the container to verify that settings remain valid:
lxc restart c1
lxc config device show c1
## login onto c1 container ##
lxc exec c1 bash
cd /dest/
ls -l
## is it read-only or read-write? ##
mkdir foo
exit

Adding a shared host directory to an LXD Container
How to remove/delete/unmount directory from an LXD container
To remove container devices such as disk named myhomedir from c1 container, run:
lxc config device remove c1 myhomedir
Device myhomedir removed from c1

Verify it:
lxc config device show c1

Add a shared host directory to an LXC/LXD container (read-write mode)
By default, the root user is not allowed to modify files inside containers from a host. It is a security feature of LXD. In other words, you need to remap your user ID if you need read-write access for mounted folders.

The subordinate gid file
Each line in /etc/subgid contains a user name and a range of subordinate group ids that user is allowed to use. This file specifies the group IDs that ordinary users can use, with the newgidmap command, to configure gid mapping in a user namespace. This is specified with three fields delimited by colons (â€œ:). Use the cat command:
cat /etc/subgid

Sample outputs:

vivek:100000:65536
Where fields are:

vivek â€“ Login name or UID on host
100000 â€“ Numerical subordinate group ID
65536 â€“ Numerical subordinate group ID count
The subordinate uid file
Again, each line in /etc/subuid contains a user name and a range of subordinate user ids that user is allowed to use. This file specifies the user IDs that ordinary users can use, with the newuidmap command, to configure uid mapping in a user namespace. To view this file, run:
cat /etc/subuid

Sample outputs:

vivek:100000:65536
How to allow LXD to remap your user ID on the host
Use the id command to find out your uid/gid:
id

Sample outputs:

uid=1000(vivek) gid=1000(vivek) groups=1000(vivek),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),115(lpadmin),116(sambashare),998(lxd)
Next, I am going to allow the LXD demon which is running as root to remap my hostâ€™s user ID inside a container:
echo "root:1000:1" | sudo tee -a /etc/subuid /etc/subgid

This is a one time set up and no need to repeat. Make sure file has been updated:
cat /etc/{subuid,subgid}

How to remap your user ID inside the container
Find UID inside the container for the user named vivek (user account must exist inside the c1):
lxc exec c1 bash
grep command '^vivek' /etc/passwd

Create a user account named if no output displayed by above grep command:
lxc exec c1 bash
adduser vivek
id vivek
exit

Type the following command to map both the UID and the GID, from the hostâ€™s UID (1000) to the c1 containerâ€™s 1000 UID (vivek):
lxc config set c1 raw.idmap "both 1000 1000"

Restart the container to settings take effect:
lxc restart c1

Finally, mount and map the directory in a read/write mode:
lxc config device add c1 myhomedir disk source=/home/vivek/ path=/home/vivek/
lxc config show c1

Test it
lxc exec c1 bash
cd /home/vivek
mkdir delta
echo "www.nixcraft.com" > test.txt
cat test.txt
rmdir delta
## back to the host ##
exit
## make sure bar.txt still exists on host ##
ls -l test.txt
cat test.txt

Linux mount directory in LXD in read and write mode
Successfully mounted hosts /home/vivek/ directory onto c1 containers in read-write mode

Conclusion
You learned how to bind-mount your Linux home directory in LXD either in read-only or read-write mode by mapping UID/GID. This feature is handy to mount high availability storage into a container. See LXD project docs for more info.


----
TO READ
https://stgraber.org/
https://stgraber.org/2017/06/15/custom-user-mappings-in-lxd-containers/
https://ubuntu.com/blog/nested-containers-in-lxd
https://ubuntu.com/blog/network-management-with-lxd-2-3
https://ubuntu.com/blog/container-to-container-networking-the-bits-have-hit-the-fan
https://ubuntu.com/blog/live-migration-in-lxd
https://ubuntu.com/blog/on-the-road-to-lean-infrastructure
https://ubuntu.com/blog/usb-hotplug-with-lxd-containers
https://ubuntu.com/blog/maas-for-the-home

















-->


<!-- vim: set sw=4 sts=4 ai si et tw=79 ft=markdown: -->
